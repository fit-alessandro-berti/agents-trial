{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3f353a-fa51-407d-a0e3-20143367c519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed: Python 3.10-3.11\n",
    "\n",
    "# requirements:\n",
    "## pm4py>=2.7.11.13\n",
    "## duckdb\n",
    "## openai\n",
    "## crewai\n",
    "## crewai[tools]\n",
    "## langchain\n",
    "## langchain-openai\n",
    "\n",
    "# you can install them with the command: pip install -U pm4py>=2.7.11.13 duckdb openai crewai crewai[tools] langchain langchain-openai\n",
    "\n",
    "# in Colab, you can uncomment the following line:\n",
    "# !pip install pm4py>=2.7.11.13 duckdb openai crewai crewai[tools] langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb949ed-f14a-44ad-8446-c0402fa7b1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the necessary requirements\n",
    "from crewai import Crew, Agent, Task\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pm4py\n",
    "import duckdb\n",
    "import os\n",
    "from crewai_tools import tool\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3313c464-4a96-4956-bc4e-6bc2386d2eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the API key (always needed!)\n",
    "os.environ[\"OPENAI_API_KEY\"] = open(\"api_key.txt\", \"r\").read()\n",
    "\n",
    "# sets the address of the APIs and the required model\n",
    "\n",
    "# DeepInfra Qwen2-72B-Instruct\n",
    "llm = ChatOpenAI(model=\"Qwen/Qwen2-72B-Instruct\", base_url=\"https://api.deepinfra.com/v1/openai/\")\n",
    "\n",
    "# OpenAI's GPT-4o\n",
    "#llm = ChatOpenAI(model=\"gpt-4o\", base_url=\"https://api.openai.com/v1\")\n",
    "\n",
    "# OpenAI's GPT-3.5-turbo\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", base_url=\"https://api.openai.com/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8ab4a4-a72a-4a41-bf79-f8fd2b23766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep a dictionary shared to all the methods\n",
    "\n",
    "global_variables = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd94e4d7-d2b4-4f60-861a-07768c6e1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the tool that can be used to get the SQL query to filter the 'protected' group (more subject to discrimination)\n",
    "\n",
    "@tool(\"Prompt containing the description of the attributes of event log.\")\n",
    "def get_prompt_base_description_of_event_log() -> str:\n",
    "    \"\"\"\n",
    "    Returns the prompt that can be used to get the base description of the attributes of the event log.\n",
    "\n",
    "    Returns\n",
    "    --------------\n",
    "    base_description_prompt\n",
    "        Base description prompt\n",
    "    \"\"\"\n",
    "    pickle.dump(global_variables, open(\"global_variables.dump\", \"wb\"))\n",
    "\n",
    "    prompt = \"Given an event log describing a process with the following directly-follows graph:\\n\\n\"\n",
    "    prompt += pm4py.llm.abstract_dfg(global_variables['dataframe'], max_len=5000, response_header=False)\n",
    "    prompt += \"\\n\\nand the following attributes:\\n\\n\"\n",
    "    prompt += pm4py.llm.abstract_log_attributes(global_variables['dataframe'], max_len=5000)\n",
    "    prompt += \"\\n\\nCould you make an hypothesis and provide me a DuckDB SQL query that I can execute to filter the dataframe on the cases in which unfairness is likely to happen? It can be an OR query (several different conditions could signal unfairness) The dataframe is called 'dataframe'. Please only a single query. The single query should only look at the case attributes, not the activities in a case. Quote the names of the attributes with a \\\" at start and at the end.\"\n",
    "    prompt += \"\\nThe SQL query has to be contained between the tags ```sql and ```\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8574fc11-0941-422f-a21c-397fcb20d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the tool that can be used to execute the SQL query. The 'protected' and 'non-protected' cases are identified and saved.\n",
    "\n",
    "@tool(\"Executes the provided SQL query.\")\n",
    "def execute_sql_query(sql_query: str):\n",
    "    \"\"\"\n",
    "    Executes the given SQL query.\n",
    "\n",
    "    Parameters\n",
    "    ----------------\n",
    "    sql_query\n",
    "        SQL query\n",
    "    \"\"\"\n",
    "    pickle.dump(global_variables, open(\"global_variables.dump\", \"wb\"))\n",
    "\n",
    "    F = open(\"sql.txt\", \"w\")\n",
    "    F.write(str(sql_query))\n",
    "    F.close()\n",
    "\n",
    "    sql_query = sql_query.split(\"```sql\")[-1].split(\"```\")[0]\n",
    "    dataframe = global_variables['dataframe']\n",
    "    dataframe_prot = duckdb.sql(sql_query).to_df()\n",
    "    cases = dataframe_prot[\"case:concept:name\"].unique()\n",
    "    dataframe_nonprot = dataframe[~dataframe[\"case:concept:name\"].isin(cases)]\n",
    "    global_variables['dataframe_prot'] = dataframe_prot\n",
    "    global_variables['dataframe_nonprot'] = dataframe_nonprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109b6761-31aa-45f2-90a0-4c18bb97a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the tool that can be used to obtain the prompt to compare the behavior in the two groups\n",
    "\n",
    "@tool(\"Prompt for process comparison between two groups.\")\n",
    "def get_prompt_for_process_comparison() -> str:\n",
    "    \"\"\"\n",
    "    Gets the prompt that should be used for process comparison.\n",
    "\n",
    "    Returns\n",
    "    --------------\n",
    "    process_comparison_prompt\n",
    "        Process comparison prompt\n",
    "    \"\"\"\n",
    "    pickle.dump(global_variables, open(\"global_variables.dump\", \"wb\"))\n",
    "\n",
    "    dataframe_prot = global_variables['dataframe_prot']\n",
    "    dataframe_nonprot = global_variables['dataframe_nonprot']\n",
    "    prompt = \"I want to identify the unfair differences between the treatment of the 'protected' group (first) and the 'unprotected' group (second). I report the process variants. Each process variant is also reported with its execution time.\"\n",
    "    prompt += \"\\n\\nProcess variants of the protected group:\"\n",
    "    prompt += pm4py.llm.abstract_variants(dataframe_prot, max_len=5000, response_header=False)\n",
    "    prompt += \"\\n\\nProcess variants of the unprotected group:\"\n",
    "    prompt += pm4py.llm.abstract_variants(dataframe_nonprot, max_len=5000, response_header=False)\n",
    "    prompt += \"\\n\\nwhich are the main differences? use your domain knowledge.\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c8b71a-778c-4246-992f-1c7614245cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads the event log in-memory using pm4py\n",
    "global_variables['dataframe'] = pm4py.read_xes(\"renting_log_high.xes.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d317c13e-a9d4-4b33-b8cf-272264d56534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the two agents:\n",
    "# - the first one is expert in identifying the protected group\n",
    "# - the second one is expert in process comparison\n",
    "# the agents have all a 'role', a 'goal', a 'backstory', and are connected to the provided LLM.\n",
    "\n",
    "pm_protected_group_identification = Agent(role=\"protected_group_identification\", goal=\"Identifying the protected group.\", backstory=\"Fairness expert.\", llm=llm)\n",
    "pm_comparison_expert = Agent(role=\"comparison_expert\", goal=\"Compare the behavior of two groups of cases.\", backstory=\"Comparison expert.\", llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de338d93-9628-4680-a007-08e06b9e0032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the two tasks for the identification of the protected group and the comparison between the 'protected' and the 'non-protected' group.\n",
    "# the first task is connected to two tools\n",
    "# the second task is connected to the last tool (for process comparison)\n",
    "protected_group_identification = Task(description=\"Retrieve a SQL query to identify the protected cases and executes that against the event log.\", expected_output=\"No output\", agent=pm_protected_group_identification, tools=[get_prompt_base_description_of_event_log, execute_sql_query])\n",
    "comparison_protected_nonprotected = Task(description=\"Comparing the behavior of the protected group against the nonprotected group.\", expected_output=\"A list of discriminations\", agent=pm_comparison_expert, tools=[get_prompt_for_process_comparison])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce633662-907e-43cd-9dc1-5c2d80c9cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the crew\n",
    "\n",
    "print(os.environ[\"OPENAI_API_KEY\"])\n",
    "crew = Crew(agents=[pm_protected_group_identification, pm_comparison_expert], tasks=[protected_group_identification, comparison_protected_nonprotected])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe613bc-71e9-4178-8e13-8241afde8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starts the crew\n",
    "\n",
    "crew.kickoff()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
