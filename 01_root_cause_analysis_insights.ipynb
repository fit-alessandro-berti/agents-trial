{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703d280-6428-41f4-91c5-c0e863f8b662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed: Python 3.10-3.11\n",
    "\n",
    "# requirements:\n",
    "## pm4py>=2.7.11.13\n",
    "## duckdb\n",
    "## openai\n",
    "## crewai\n",
    "## crewai[tools]\n",
    "## langchain\n",
    "## langchain-openai\n",
    "\n",
    "# you can install them with the command: pip install -U pm4py>=2.7.11.13 duckdb openai crewai crewai[tools] langchain langchain-openai\n",
    "\n",
    "# in Colab, you can uncomment the following line:\n",
    "# !pip install pm4py>=2.7.11.13 duckdb openai crewai crewai[tools] langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3075a0e0-fb74-4f38-9a1a-0e25cf281ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the necessary requirements\n",
    "from crewai import Crew, Agent, Task\n",
    "from langchain_openai import ChatOpenAI\n",
    "import pm4py\n",
    "import duckdb\n",
    "import os\n",
    "from crewai_tools import tool\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b8a5a1-d95e-4473-a164-a5a232c1dacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the API key (always needed!)\n",
    "os.environ[\"OPENAI_API_KEY\"] = open(\"api_key.txt\", \"r\").read()\n",
    "\n",
    "# sets the address of the APIs and the required model\n",
    "\n",
    "# DeepInfra Qwen2-7B-Instruct\n",
    "llm = ChatOpenAI(model=\"Qwen/Qwen2-7B-Instruct\", base_url=\"https://api.deepinfra.com/v1/openai/\")\n",
    "\n",
    "# OpenAI's GPT-4o\n",
    "#llm = ChatOpenAI(model=\"gpt-4o\", base_url=\"https://api.openai.com/v1\")\n",
    "\n",
    "# OpenAI's GPT-3.5-turbo\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", base_url=\"https://api.openai.com/v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db1a2e-ae2f-43cc-9c3c-fd1a9a837b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reads the event log in-memory using pm4py\n",
    "log = pm4py.read_xes(\"renting_log_high.xes.gz\")\n",
    "\n",
    "# computes the DFG abstraction\n",
    "dfg_abstraction = pm4py.llm.abstract_dfg(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b433ab3f-be83-42b1-af42-1810c342a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines three agents:\n",
    "# - the first one specialized in root cause analysis identification\n",
    "# - the second one specialized in explaining the root cause analysis insights\n",
    "# - the third one acting as a judge, giving a score from 1.0 to 10.0 to the previous insights\n",
    "# the agents have all a 'role', a 'goal', a 'backstory', and are connected to the provided LLM.\n",
    "\n",
    "pm_root_cause_analyst = Agent(role=\"root_cause_analyst\", goal=\"Perform root cause analysis in process mining.\", backstory=\"Finds all the root causes of the performance issues.\", llm=llm)\n",
    "pm_root_cause_explainer = Agent(role=\"root_cause_explainer\", goal=\"Explaining process mining insights to non-technical people.\", backstory=\"Very detailed analyst.\", llm=llm)\n",
    "pm_insights_grader = Agent(role=\"insights_grader\", goal=\"Giving a score to the process mining insights proposed by others.\", backstory=\"Judge.\", llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92211564-4968-4d80-b74d-8baf8527a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the tasks of the three agents\n",
    "\n",
    "root_cause_analysis = Task(description=\"Find the root causes of the performance issues in the process. Only process and data specific considerations, not general considerations. DFG abstraction: {dfg_abstraction}\", expected_output=\"The chain of thought related to the insight\", agent=pm_root_cause_analyst)\n",
    "root_cause_chain_of_thought = Task(description=\"Explain the first of the provided insight in detail. Original DFG abstraction: {dfg_abstraction}\", expected_output=\"The chain of thought related to the insight\", agent=pm_root_cause_explainer)\n",
    "root_cause_grader = Task(description=\"Provide a grade from 1.0 (minimum) to 10.0 (maximum) for all the provided root cause insights. Original DFG abstraction: {dfg_abstraction}\", expected_output=\"A list of insights, each accompanied by a grade.\", agent=pm_insights_grader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9542afc7-cb66-4bab-b866-cfd126337495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines the crew\n",
    "\n",
    "print(os.environ[\"OPENAI_API_KEY\"])\n",
    "crew = Crew(agents=[pm_root_cause_analyst, pm_root_cause_explainer, pm_insights_grader], tasks=[root_cause_analysis, root_cause_chain_of_thought, root_cause_grader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1656a42-0677-4498-bf9c-b20b01bd0995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# starts the crew\n",
    "\n",
    "crew.kickoff({\"dfg_abstraction\": dfg_abstraction})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
